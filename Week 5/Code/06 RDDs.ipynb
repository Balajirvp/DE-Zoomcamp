{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40d2766",
   "metadata": {},
   "source": [
    "## Section I\n",
    "\n",
    "Operations on Spark RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722b5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f88bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('D:/data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4913cf",
   "metadata": {},
   "source": [
    "#### We will be Implementing the below SQL code using RDDs\n",
    "\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone, \n",
    "    \n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records \n",
    "FROM\n",
    "    green \\\n",
    "WHERE \n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00' \\\n",
    "GROUP BY\n",
    "    1, 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a91beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "\n",
    "rdd = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f594261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b797f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(year=2020, month=1, day=1)\n",
    "\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start\n",
    "\n",
    "rdd.filter(filter_outliers).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a85921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used this row for testing purpose\n",
    "\n",
    "rows = rdd.take(10)\n",
    "row = rows[0]\n",
    "\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb29aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "\n",
    "def prepare_for_grouping(row): \n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91dcfda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 23, 13, 0), 74), (44.97, 1)),\n",
       " ((datetime.datetime(2020, 1, 20, 15, 0), 67), (33.45, 1)),\n",
       " ((datetime.datetime(2020, 1, 15, 20, 0), 260), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 5, 16, 0), 82), (8.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 29, 19, 0), 166), (12.74, 1))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(filter_outliers).map(prepare_for_grouping).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308bf061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 20, 15, 0), 67), (79.5, 3)),\n",
       " ((datetime.datetime(2020, 1, 16, 8, 0), 41), (736.1399999999994, 54)),\n",
       " ((datetime.datetime(2020, 1, 20, 15, 0), 75), (609.0, 47)),\n",
       " ((datetime.datetime(2020, 1, 17, 21, 0), 74), (594.87, 39)),\n",
       " ((datetime.datetime(2020, 1, 3, 9, 0), 61), (142.21, 9))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4\n",
    "\n",
    "def calculate_revenue(left_value, right_value):\n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return (output_amount, output_count)\n",
    "\n",
    "rdd.filter(filter_outliers).map(prepare_for_grouping).reduceByKey(calculate_revenue).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2fa321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RevenueRow(hour=datetime.datetime(2020, 1, 20, 15, 0), zone=67, revenue=79.5, count=3),\n",
       " RevenueRow(hour=datetime.datetime(2020, 1, 16, 8, 0), zone=41, revenue=736.1399999999994, count=54),\n",
       " RevenueRow(hour=datetime.datetime(2020, 1, 20, 15, 0), zone=75, revenue=609.0, count=47),\n",
       " RevenueRow(hour=datetime.datetime(2020, 1, 17, 21, 0), zone=74, revenue=594.87, count=39),\n",
       " RevenueRow(hour=datetime.datetime(2020, 1, 3, 9, 0), zone=61, revenue=142.21, count=9)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])\n",
    "\n",
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0], \n",
    "        zone=row[0][1],\n",
    "        revenue=row[1][0],\n",
    "        count=row[1][1]\n",
    "    )\n",
    "\n",
    "rdd.filter(filter_outliers).map(prepare_for_grouping).reduceByKey(calculate_revenue).map(unwrap).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7623de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----------------+-----+\n",
      "|               hour|zone|          revenue|count|\n",
      "+-------------------+----+-----------------+-----+\n",
      "|2020-01-20 15:00:00|  67|             79.5|    3|\n",
      "|2020-01-16 08:00:00|  41|736.1399999999994|   54|\n",
      "|2020-01-20 15:00:00|  75|            609.0|   47|\n",
      "|2020-01-17 21:00:00|  74|           594.87|   39|\n",
      "|2020-01-03 09:00:00|  61|           142.21|    9|\n",
      "+-------------------+----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you don't specify the schema in toDF(), it takes a bit longer to run as it tries to find what schema to implement it in\n",
    "\n",
    "rdd.filter(filter_outliers).map(prepare_for_grouping).reduceByKey(calculate_revenue).map(unwrap).toDF().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a800b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----------------+-----+\n",
      "|               hour|zone|          revenue|count|\n",
      "+-------------------+----+-----------------+-----+\n",
      "|2020-01-20 15:00:00|  67|             79.5|    3|\n",
      "|2020-01-16 08:00:00|  41|736.1399999999994|   54|\n",
      "|2020-01-20 15:00:00|  75|            609.0|   47|\n",
      "|2020-01-17 21:00:00|  74|           594.87|   39|\n",
      "|2020-01-03 09:00:00|  61|           142.21|    9|\n",
      "+-------------------+----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 6\n",
    "\n",
    "from pyspark.sql import types\n",
    "\n",
    "result_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True),\n",
    "    types.StructField('zone', types.IntegerType(), True),\n",
    "    types.StructField('revenue', types.DoubleType(), True),\n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "])\n",
    "\n",
    "rdd.filter(filter_outliers).map(prepare_for_grouping).reduceByKey(calculate_revenue).map(unwrap).toDF(result_schema).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d64007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .reduceByKey(calculate_revenue) \\\n",
    "    .map(unwrap) \\\n",
    "    .toDF(result_schema) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72399664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.write.parquet('D:/tmp/green-revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1c598",
   "metadata": {},
   "source": [
    "## Section II\n",
    "\n",
    "Spark RDD mapPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f3c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "duration_rdd = df_green \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "436aca6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, DOLocationID=130, trip_distance=12.77),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, DOLocationID=39, trip_distance=8.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, DOLocationID=157, trip_distance=1.27),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, DOLocationID=83, trip_distance=1.25),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, DOLocationID=42, trip_distance=1.84)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbdfa98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#model = ...\n",
    "\n",
    "def model_predict(df):\n",
    "#     y_pred = model.predict(df)\n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    df['predicted_duration'] = predictions\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b00263cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pandas(Index=0, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-23 13:10:15'), PULocationID=74, DOLocationID=130, trip_distance=12.77, predicted_duration=63.849999999999994),\n",
       " Pandas(Index=1, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-20 15:09:00'), PULocationID=67, DOLocationID=39, trip_distance=8.0, predicted_duration=40.0),\n",
       " Pandas(Index=2, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-15 20:23:41'), PULocationID=260, DOLocationID=157, trip_distance=1.27, predicted_duration=6.35),\n",
       " Pandas(Index=3, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-05 16:32:26'), PULocationID=82, DOLocationID=83, trip_distance=1.25, predicted_duration=6.25),\n",
       " Pandas(Index=4, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-29 19:22:42'), PULocationID=166, DOLocationID=42, trip_distance=1.84, predicted_duration=9.200000000000001)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf0ed02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicts = duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch)\\\n",
    "    .toDF() \\\n",
    "    .drop('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8a6821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|predicted_duration|\n",
      "+------------------+\n",
      "|63.849999999999994|\n",
      "|              40.0|\n",
      "|              6.35|\n",
      "|              6.25|\n",
      "| 9.200000000000001|\n",
      "|               3.8|\n",
      "|16.599999999999998|\n",
      "|             11.05|\n",
      "|               4.5|\n",
      "|              30.5|\n",
      "|               8.7|\n",
      "|5.8999999999999995|\n",
      "|              11.0|\n",
      "|              15.2|\n",
      "|              4.25|\n",
      "|25.299999999999997|\n",
      "|7.8500000000000005|\n",
      "|              34.0|\n",
      "| 5.300000000000001|\n",
      "|              6.15|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_predicts.select('predicted_duration').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
